{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4JTdNglD0gc",
        "outputId": "95815836-e9d1-49ba-f288-acc5419067ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'urdu_ghazals_rekhta' already exists and is not an empty directory.\n",
            "replace urdu_ghazals_rekhta/dataset/dataset/ahmad-faraz/ur/silsile-tod-gayaa-vo-sabhii-jaate-jaate-ahmad-faraz-ghazals? [y]es, [n]o, [A]ll, [N]one, [r]ename: Root exists: True\n",
            "Example authors (first 8): ['ahmad-faraz', 'akbar-allahabadi', 'allama-iqbal', 'altaf-hussain-hali', 'ameer-khusrau', 'bahadur-shah-zafar', 'dagh-dehlvi', 'fahmida-riaz']\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"urdu-to-roman-urdu-translator.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1WnSE_S2eypz48WPQ-Vo8o_WoYMQqIBTJ\n",
        "\n",
        "### Clone repo & unzip dataset\n",
        "\"\"\"\n",
        "\n",
        "# Cell 1: Clone repo & unzip dataset\n",
        "!git clone https://github.com/amir9ume/urdu_ghazals_rekhta.git\n",
        "!unzip -q urdu_ghazals_rekhta/dataset/dataset.zip -d urdu_ghazals_rekhta/dataset/\n",
        "\n",
        "from pathlib import Path\n",
        "root = Path(\"urdu_ghazals_rekhta/dataset/dataset\")\n",
        "print(\"Root exists:\", root.exists())\n",
        "print(\"Example authors (first 8):\", [p.name for p in sorted(root.iterdir()) if p.is_dir()][:8])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Build parallel dataset (Urdu -> Roman)\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path(\"urdu_ghazals_rekhta/dataset/dataset\")\n",
        "pairs = []\n",
        "for author in sorted(root.iterdir()):\n",
        "    if not author.is_dir():\n",
        "        continue\n",
        "    ur_dir = author / \"ur\"\n",
        "    en_dir = author / \"en\"\n",
        "    if not ur_dir.exists() or not en_dir.exists():\n",
        "        continue\n",
        "    for ur_file in sorted(ur_dir.iterdir()):\n",
        "        en_file = en_dir / ur_file.name\n",
        "        if not en_file.exists():\n",
        "            continue\n",
        "        ur_lines = open(ur_file, encoding=\"utf-8\", errors=\"ignore\").read().splitlines()\n",
        "        en_lines = open(en_file, encoding=\"utf-8\", errors=\"ignore\").read().splitlines()\n",
        "        for u,e in zip(ur_lines, en_lines):\n",
        "            if u and e:\n",
        "                pairs.append((u.strip(), e.strip()))\n",
        "df = pd.DataFrame(pairs, columns=[\"urdu\",\"roman\"])\n",
        "print(\"Collected pairs:\", len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "DH-viwvGED0_",
        "outputId": "321f9603-26f8-4e79-9149-e0dd81e333c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected pairs: 21003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        urdu  \\\n",
              "0        آنکھ سے دور نہ ہو دل سے اتر جائے گا   \n",
              "1         وقت کا کیا ہے گزرتا ہے گزر جائے گا   \n",
              "2           اتنا مانوس نہ ہو خلوت غم سے اپنی   \n",
              "3  تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا   \n",
              "4          ڈوبتے ڈوبتے کشتی کو اچھالا دے دوں   \n",
              "\n",
              "                                        roman  \n",
              "0      aañkh se duur na ho dil se utar jā.egā  \n",
              "1    vaqt kā kyā hai guzartā hai guzar jā.egā  \n",
              "2     itnā mānūs na ho ḳhalvat-e-ġham se apnī  \n",
              "3  tū kabhī ḳhud ko bhī dekhegā to Dar jā.egā  \n",
              "4       Dūbte Dūbte kashtī ko uchhālā de duuñ  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f4236b0-a6c6-46bd-a138-1b8e29388902\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>urdu</th>\n",
              "      <th>roman</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>آنکھ سے دور نہ ہو دل سے اتر جائے گا</td>\n",
              "      <td>aañkh se duur na ho dil se utar jā.egā</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>وقت کا کیا ہے گزرتا ہے گزر جائے گا</td>\n",
              "      <td>vaqt kā kyā hai guzartā hai guzar jā.egā</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اتنا مانوس نہ ہو خلوت غم سے اپنی</td>\n",
              "      <td>itnā mānūs na ho ḳhalvat-e-ġham se apnī</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا</td>\n",
              "      <td>tū kabhī ḳhud ko bhī dekhegā to Dar jā.egā</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ڈوبتے ڈوبتے کشتی کو اچھالا دے دوں</td>\n",
              "      <td>Dūbte Dūbte kashtī ko uchhālā de duuñ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f4236b0-a6c6-46bd-a138-1b8e29388902')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f4236b0-a6c6-46bd-a138-1b8e29388902 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f4236b0-a6c6-46bd-a138-1b8e29388902');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5795826b-4bbe-4a45-a15e-13e23c1e01fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5795826b-4bbe-4a45-a15e-13e23c1e01fd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5795826b-4bbe-4a45-a15e-13e23c1e01fd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 21003,\n  \"fields\": [\n    {\n      \"column\": \"urdu\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20947,\n        \"samples\": [\n          \"\\u06c1\\u0627\\u06ba \\u062c\\u0627\\u06ba \\u06a9\\u06d2 \\u0632\\u06cc\\u0627\\u06ba \\u06a9\\u06cc \\u06c1\\u0645 \\u06a9\\u0648 \\u0628\\u06be\\u06cc \\u062a\\u0634\\u0648\\u06cc\\u0634 \\u06c1\\u06d2 \\u0644\\u06cc\\u06a9\\u0646 \\u06a9\\u06cc\\u0627 \\u06a9\\u06cc\\u062c\\u06d2\",\n          \"\\u0646\\u06c1 \\u0627\\u062f\\u0627\\u0626\\u06d2 \\u06a9\\u0627\\u0641\\u0631\\u0627\\u0646\\u06c1 \\u0646\\u06c1 \\u062a\\u0631\\u0627\\u0634 \\u0622\\u0632\\u0631\\u0627\\u0646\\u06c1\",\n          \"\\u062c\\u0648 \\u062a\\u0645\\u06c1\\u0627\\u0631\\u06cc \\u0645\\u0627\\u0646 \\u0644\\u06cc\\u06ba \\u0646\\u0627\\u0635\\u062d\\u0627 \\u062a\\u0648 \\u0631\\u06c1\\u06d2 \\u06af\\u0627 \\u062f\\u0627\\u0645\\u0646 \\u062f\\u0644 \\u0645\\u06cc\\u06ba \\u06a9\\u06cc\\u0627\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roman\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20947,\n        \"samples\": [\n          \"haa\\u00f1 jaa\\u00f1 ke ziy\\u0101\\u00f1 k\\u012b ham ko bh\\u012b tashv\\u012bsh hai lekin ky\\u0101 kiije\",\n          \"na ad\\u0101-e-k\\u0101fir\\u0101na na tar\\u0101sh-e-\\u0101zr\\u0101na\",\n          \"jo tumh\\u0101r\\u012b maan le\\u00f1 n\\u0101seh\\u0101 to raheg\\u0101 d\\u0101man-e-dil me\\u00f1 ky\\u0101\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 3: Normalize roman side and clean Urdu (simple rules)\n",
        "import re\n",
        "\n",
        "def normalize_roman(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"<unk>\", \"\")\n",
        "    # normalize some diacritics to ascii-ish forms\n",
        "    reps = {\"ā\":\"a\",\"ī\":\"i\",\"ū\":\"u\",\"ḳ\":\"q\",\"ġ\":\"gh\",\"ñ\":\"n\",\"ṭ\":\"t\",\"ḍ\":\"d\",\"ś\":\"sh\",\"’\":\"'\", \"—\":\" \"}\n",
        "    for a,b in reps.items():\n",
        "        text = text.replace(a,b)\n",
        "    # keep common roman characters, digits, apostrophe and spaces\n",
        "    text = re.sub(r\"[^a-z0-9'\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def clean_urdu(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"\\s+\", \" \", text.strip())\n",
        "    return text\n",
        "\n",
        "df[\"roman\"] = df[\"roman\"].apply(normalize_roman)\n",
        "df[\"urdu\"] = df[\"urdu\"].apply(clean_urdu)\n",
        "# drop very short / empty lines\n",
        "df = df[(df[\"roman\"].str.len() > 1) & (df[\"urdu\"].str.len() > 0)].reset_index(drop=True)\n",
        "print(\"After cleaning:\", len(df))\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "xml0Gw1xTtID",
        "outputId": "f592c6d8-6413-4453-b965-4e50ce57f45f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After cleaning: 21003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       urdu  \\\n",
              "15963   بیاد گرمیٔ صحبت بہ رنگ شعلہ دہکے ہے   \n",
              "2167   خودی کی موت ہے اندیشہ ہائے گوناں گوں   \n",
              "12532             تاب کس کو جو حال میرؔ سنے   \n",
              "6815              زخم پنہاں کی ہے نشانی بھی   \n",
              "3716   کیا تماشا ہے رگ لیلیٰ میں ڈوبا نیشتر   \n",
              "\n",
              "                                                   roman  \n",
              "15963  bayad e garmi e sohbat ba rang e sho ala dahke...  \n",
              "2167             qhudi ki maut hai andesha ha e guna gun  \n",
              "12532                    taab kis ko jo hal e 'mir' sune  \n",
              "6815                   zaqhm e pinhan ki hai nishani bhi  \n",
              "3716       kya tamasha hai rag e laila men duuba neshtar  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a966ecf-0871-4bae-bf87-8eba677d6feb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>urdu</th>\n",
              "      <th>roman</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15963</th>\n",
              "      <td>بیاد گرمیٔ صحبت بہ رنگ شعلہ دہکے ہے</td>\n",
              "      <td>bayad e garmi e sohbat ba rang e sho ala dahke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2167</th>\n",
              "      <td>خودی کی موت ہے اندیشہ ہائے گوناں گوں</td>\n",
              "      <td>qhudi ki maut hai andesha ha e guna gun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12532</th>\n",
              "      <td>تاب کس کو جو حال میرؔ سنے</td>\n",
              "      <td>taab kis ko jo hal e 'mir' sune</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6815</th>\n",
              "      <td>زخم پنہاں کی ہے نشانی بھی</td>\n",
              "      <td>zaqhm e pinhan ki hai nishani bhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3716</th>\n",
              "      <td>کیا تماشا ہے رگ لیلیٰ میں ڈوبا نیشتر</td>\n",
              "      <td>kya tamasha hai rag e laila men duuba neshtar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a966ecf-0871-4bae-bf87-8eba677d6feb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a966ecf-0871-4bae-bf87-8eba677d6feb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a966ecf-0871-4bae-bf87-8eba677d6feb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1070ee12-5912-4c1c-b4ac-b4b918258744\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1070ee12-5912-4c1c-b4ac-b4b918258744')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1070ee12-5912-4c1c-b4ac-b4b918258744 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"urdu\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u062e\\u0648\\u062f\\u06cc \\u06a9\\u06cc \\u0645\\u0648\\u062a \\u06c1\\u06d2 \\u0627\\u0646\\u062f\\u06cc\\u0634\\u06c1 \\u06c1\\u0627\\u0626\\u06d2 \\u06af\\u0648\\u0646\\u0627\\u06ba \\u06af\\u0648\\u06ba\",\n          \"\\u06a9\\u06cc\\u0627 \\u062a\\u0645\\u0627\\u0634\\u0627 \\u06c1\\u06d2 \\u0631\\u06af \\u0644\\u06cc\\u0644\\u06cc\\u0670 \\u0645\\u06cc\\u06ba \\u0688\\u0648\\u0628\\u0627 \\u0646\\u06cc\\u0634\\u062a\\u0631\",\n          \"\\u062a\\u0627\\u0628 \\u06a9\\u0633 \\u06a9\\u0648 \\u062c\\u0648 \\u062d\\u0627\\u0644 \\u0645\\u06cc\\u0631\\u0614 \\u0633\\u0646\\u06d2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roman\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"qhudi ki maut hai andesha ha e guna gun\",\n          \"kya tamasha hai rag e laila men duuba neshtar\",\n          \"taab kis ko jo hal e 'mir' sune\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 4: Shuffle and split 50/25/25\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "df_shuf = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train, tmp = train_test_split(df_shuf, test_size=0.5, random_state=42)\n",
        "valid, test = train_test_split(tmp, test_size=0.5, random_state=42)\n",
        "\n",
        "train.to_csv(\"data/train.tsv\", sep=\"\\t\", index=False)\n",
        "valid.to_csv(\"data/valid.tsv\", sep=\"\\t\", index=False)\n",
        "test.to_csv(\"data/test.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Saved splits: train/valid/test =\", len(train), len(valid), len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQv8mPfET1LM",
        "outputId": "e60dd04f-2a30-4ab3-b9cb-b709416889d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved splits: train/valid/test = 10501 5251 5251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Learn BPE from scratch on roman training data\n",
        "from collections import Counter, defaultdict\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Read roman training lines (space-separated words)\n",
        "train_roman_lines = train[\"roman\"].tolist()\n",
        "\n",
        "# Prepare corpus as list of tokenized words represented as tuple of symbols ending with </w>\n",
        "def get_tokenized_corpus(lines):\n",
        "    corpus = []\n",
        "    for line in lines:\n",
        "        for word in line.strip().split():\n",
        "            # represent a word as list of characters with end-of-word marker\n",
        "            symbols = list(word) + [\"</w>\"]\n",
        "            corpus.append(tuple(symbols))\n",
        "    return corpus\n",
        "\n",
        "corpus = get_tokenized_corpus(train_roman_lines)\n",
        "\n",
        "# BPE helpers\n",
        "def get_stats(corpus):\n",
        "    pairs = defaultdict(int)\n",
        "    for word in corpus:\n",
        "        prev = word[0]\n",
        "        for ch in word[1:]:\n",
        "            pairs[(prev,ch)] += 1\n",
        "            prev = ch\n",
        "    return pairs\n",
        "\n",
        "def merge_pair(pair, corpus):\n",
        "    # pair is a tuple (a,b); merge occurrences in corpus\n",
        "    a,b = pair\n",
        "    merged = a + b\n",
        "    new_corpus = []\n",
        "    for word in corpus:\n",
        "        new_word = []\n",
        "        i = 0\n",
        "        while i < len(word):\n",
        "            # if pair matches at position i\n",
        "            if i < len(word)-1 and word[i] == a and word[i+1] == b:\n",
        "                new_word.append(merged)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_word.append(word[i])\n",
        "                i += 1\n",
        "        new_corpus.append(tuple(new_word))\n",
        "    return new_corpus\n",
        "\n",
        "def learn_bpe(corpus, num_merges=2000, verbose=True):\n",
        "    corpus = list(corpus)\n",
        "    merges = []\n",
        "    for i in range(num_merges):\n",
        "        pairs = get_stats(corpus)\n",
        "        if not pairs:\n",
        "            break\n",
        "        best = max(pairs, key=pairs.get)\n",
        "        merges.append(best)\n",
        "        corpus = merge_pair(best, corpus)\n",
        "        if verbose and (i+1) % 100 == 0:\n",
        "            print(f\"Merges learned: {i+1}\")\n",
        "    return merges, corpus\n",
        "\n",
        "# Learn merges (you can adjust num_merges for experiments; suggested 1500-2500)\n",
        "N_MERGES = 2000  # Adjustable for experiments\n",
        "print(\"Learning BPE merges (this may take a while)...\")\n",
        "bpe_merges, final_corpus = learn_bpe(corpus, num_merges=N_MERGES, verbose=True)\n",
        "print(\"Learned merges:\", len(bpe_merges))\n",
        "\n",
        "# Build token vocabulary (unique tokens in final_corpus)\n",
        "tokens = set()\n",
        "for word in final_corpus:\n",
        "    tokens.update(word)\n",
        "# ensure common special tokens\n",
        "specials = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
        "vocab_tokens = specials + sorted(list(tokens))\n",
        "bpe_token_to_id = {tok: idx for idx, tok in enumerate(vocab_tokens)}\n",
        "bpe_id_to_token = {idx: tok for tok, idx in bpe_token_to_id.items()}\n",
        "\n",
        "# Save merges and vocab\n",
        "os.makedirs(\"data/bpe_from_scratch\", exist_ok=True)\n",
        "with open(\"data/bpe_from_scratch/merges.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump([list(m) for m in bpe_merges], f, ensure_ascii=False, indent=2)\n",
        "with open(\"data/bpe_from_scratch/vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(vocab_tokens, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"BPE vocab size:\", len(bpe_token_to_id))\n",
        "\n",
        "# BPE encode function that applies merges learned above\n",
        "def bpe_encode_word(word, merges):\n",
        "    # initial symbols\n",
        "    symbols = list(word) + [\"</w>\"]\n",
        "    symbols = symbols.copy()\n",
        "    merges_set = {tuple(m): i for i,m in enumerate(merges)}  # map to rank for tie-break\n",
        "    while True:\n",
        "        pairs = [(symbols[i], symbols[i+1]) for i in range(len(symbols)-1)]\n",
        "        # find candidate pairs present in merges\n",
        "        candidates = [(p, merges_set.get(p, None)) for p in pairs]\n",
        "        # choose leftmost pair that appears earliest in merges (i.e., smallest index)\n",
        "        best_pair, best_rank = None, None\n",
        "        for p, r in candidates:\n",
        "            if r is not None:\n",
        "                if best_rank is None or r < best_rank:\n",
        "                    best_pair, best_rank = p, r\n",
        "        if best_pair is None:\n",
        "            break\n",
        "        # merge all occurrences of best_pair\n",
        "        a,b = best_pair\n",
        "        merged = a+b\n",
        "        new_symbols = []\n",
        "        i = 0\n",
        "        while i < len(symbols):\n",
        "            if i < len(symbols)-1 and symbols[i] == a and symbols[i+1] == b:\n",
        "                new_symbols.append(merged)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_symbols.append(symbols[i])\n",
        "                i += 1\n",
        "        symbols = new_symbols\n",
        "    return symbols  # list of BPE tokens (with possible merged tokens and </w>)\n",
        "\n",
        "def bpe_encode_text(text, merges=bpe_merges):\n",
        "    # encodes a full line -> list of tokens (strings)\n",
        "    toks = []\n",
        "    for word in text.strip().split():\n",
        "        w_toks = bpe_encode_word(word, merges)\n",
        "        toks.extend(w_toks)\n",
        "    return toks\n",
        "\n",
        "# quick example\n",
        "sample = train_roman_lines[0] if train_roman_lines else \"example\"\n",
        "print(\"Example roman line:\", sample)\n",
        "print(\"BPE encoded tokens (first 30):\", bpe_encode_text(sample)[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQITotAkT7z9",
        "outputId": "d93f8ed6-520d-4f78-c378-fac5c85802c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning BPE merges (this may take a while)...\n",
            "Merges learned: 100\n",
            "Merges learned: 200\n",
            "Merges learned: 300\n",
            "Merges learned: 400\n",
            "Merges learned: 500\n",
            "Merges learned: 600\n",
            "Merges learned: 700\n",
            "Merges learned: 800\n",
            "Merges learned: 900\n",
            "Merges learned: 1000\n",
            "Merges learned: 1100\n",
            "Merges learned: 1200\n",
            "Merges learned: 1300\n",
            "Merges learned: 1400\n",
            "Merges learned: 1500\n",
            "Merges learned: 1600\n",
            "Merges learned: 1700\n",
            "Merges learned: 1800\n",
            "Merges learned: 1900\n",
            "Merges learned: 2000\n",
            "Learned merges: 2000\n",
            "BPE vocab size: 1981\n",
            "Example roman line: chaman zangar hai a ina e bad e bahari ka\n",
            "BPE encoded tokens (first 30): ['chaman</w>', 'za', 'n', 'gar</w>', 'hai</w>', 'a</w>', 'ina</w>', 'e</w>', 'bad</w>', 'e</w>', 'baha', 'ri</w>', 'ka</w>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Urdu character-level vocabulary\n",
        "src_vocab = {\"<pad>\":0, \"<sos>\":1, \"<eos>\":2, \"<unk>\":3}\n",
        "for line in train[\"urdu\"]:\n",
        "    for ch in line:\n",
        "        if ch not in src_vocab:\n",
        "            src_vocab[ch] = len(src_vocab)\n",
        "\n",
        "print(\"Urdu vocab size:\", len(src_vocab))\n",
        "# invert mapping for decoding if needed\n",
        "src_id_to_char = {i:c for c,i in src_vocab.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYbUZvKGUFwi",
        "outputId": "f9fc03b1-d014-4064-9055-bee1792d8d5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Urdu vocab size: 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 7: Dataset & DataLoaders (uses our bpe_encode_text & src_vocab)\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "PAD_IDX_SRC = src_vocab[\"<pad>\"]\n",
        "PAD_IDX_TGT = bpe_token_to_id[\"<pad>\"]\n",
        "SOS_ID = bpe_token_to_id[\"<sos>\"]\n",
        "EOS_ID = bpe_token_to_id[\"<eos>\"]\n",
        "UNK_ID = bpe_token_to_id[\"<unk>\"]\n",
        "\n",
        "MAX_SRC_LEN = 80\n",
        "MAX_TGT_LEN = 80\n",
        "\n",
        "class GhazalDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.src_lines = df[\"urdu\"].tolist()\n",
        "        self.tgt_lines = df[\"roman\"].tolist()\n",
        "    def __len__(self):\n",
        "        return len(self.src_lines)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src_lines[idx], self.tgt_lines[idx]\n",
        "\n",
        "def encode_src_line(line):\n",
        "    ids = [src_vocab.get(ch, src_vocab[\"<unk>\"]) for ch in list(line)]\n",
        "    ids = [src_vocab[\"<sos>\"]] + ids[:MAX_SRC_LEN-2] + [src_vocab[\"<eos>\"]]\n",
        "    return ids\n",
        "\n",
        "def encode_tgt_line(line):\n",
        "    toks = bpe_encode_text(line)  # list of token strings\n",
        "    ids = [bpe_token_to_id.get(t, UNK_ID) for t in toks]\n",
        "    ids = [SOS_ID] + ids[:MAX_TGT_LEN-2] + [EOS_ID]\n",
        "    return ids\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    src_lens, tgt_lens = [], []\n",
        "    for s,t in batch:\n",
        "        src_ids = torch.tensor(encode_src_line(s), dtype=torch.long)\n",
        "        tgt_ids = torch.tensor(encode_tgt_line(t), dtype=torch.long)\n",
        "        src_batch.append(src_ids); tgt_batch.append(tgt_ids)\n",
        "        src_lens.append(src_ids.size(0)); tgt_lens.append(tgt_ids.size(0))\n",
        "    src_pad = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=PAD_IDX_SRC)\n",
        "    tgt_pad = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=PAD_IDX_TGT)\n",
        "    return src_pad, torch.tensor(src_lens, dtype=torch.long), tgt_pad, torch.tensor(tgt_lens, dtype=torch.long)\n",
        "\n",
        "# Adjustable for experiments\n",
        "BATCH_SIZE = 64  # Suggested: 32, 64, 128\n",
        "\n",
        "train_ds = GhazalDataset(train)\n",
        "valid_ds = GhazalDataset(valid)\n",
        "test_ds = GhazalDataset(test)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=1, pin_memory=True)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=1, pin_memory=True)\n",
        "\n",
        "# quick check\n",
        "batch = next(iter(train_dl))\n",
        "print(\"Batch shapes src/tgt:\", batch[0].shape, batch[2].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7poSkhoUf9I",
        "outputId": "491fee1f-cd3e-4375-fd0b-44c624b1f2f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shapes src/tgt: torch.Size([64, 46]) torch.Size([64, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Model definitions without Attention (Vanilla BiLSTM Encoder-Decoder)\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# Adjustable hyperparameters for experiments\n",
        "EMB_DIM = 256  # Suggested: 128, 256, 512\n",
        "ENC_HID = 256 # Suggested: 256, 512\n",
        "DEC_HID = 256  # Suggested: 256, 512\n",
        "ENC_LAYERS = 2  # Suggested: 1, 2, 3, 4\n",
        "DEC_LAYERS = 4  # Suggested: 2, 3, 4\n",
        "DROPOUT = 0.3  # Suggested: 0.1, 0.3, 0.5\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim=EMB_DIM, enc_hidden=ENC_HID, n_layers=ENC_LAYERS, dropout=DROPOUT, pad_idx=PAD_IDX_SRC):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(emb_dim, enc_hidden, num_layers=n_layers,\n",
        "                           bidirectional=True, batch_first=True,\n",
        "                           dropout=dropout if n_layers > 1 else 0.0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.enc_hidden = enc_hidden\n",
        "\n",
        "    def forward(self, src, src_lens):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded, src_lens.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        packed_out, (h_n, c_n) = self.rnn(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
        "        return out, (h_n, c_n)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim=EMB_DIM, dec_hidden=DEC_HID, n_layers=DEC_LAYERS, dropout=DROPOUT, pad_idx=PAD_IDX_TGT):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(emb_dim, dec_hidden,\n",
        "                           num_layers=n_layers, batch_first=True,\n",
        "                           dropout=dropout if n_layers > 1 else 0.0)\n",
        "        self.fc_out = nn.Linear(dec_hidden + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.dec_hidden = dec_hidden\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "    def forward(self, input_step, hidden):\n",
        "        emb = self.dropout(self.embedding(input_step).unsqueeze(1))  # [B,1,emb]\n",
        "        out, hidden = self.rnn(emb, hidden)\n",
        "        out = out.squeeze(1)\n",
        "        emb = emb.squeeze(1)\n",
        "        pred = self.fc_out(torch.cat((out, emb), dim=1))  # [B,V]\n",
        "        return pred, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, enc_hidden=ENC_HID, dec_hidden=DEC_HID):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.h_proj = nn.Linear(enc_hidden*2, dec_hidden)\n",
        "        self.c_proj = nn.Linear(enc_hidden*2, dec_hidden)\n",
        "\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        B = src.size(0)\n",
        "        T = tgt.size(1)\n",
        "        V = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(B, T, V).to(src.device)\n",
        "\n",
        "        enc_out, (h_n, c_n) = self.encoder(src, src_lens)\n",
        "\n",
        "        top_fwd, top_bwd = h_n[-2,:,:], h_n[-1,:,:]\n",
        "        top_c_fwd, top_c_bwd = c_n[-2,:,:], c_n[-1,:,:]\n",
        "        h0 = torch.tanh(self.h_proj(torch.cat((top_fwd, top_bwd), dim=1)))\n",
        "        c0 = torch.tanh(self.c_proj(torch.cat((top_c_fwd, top_c_bwd), dim=1)))\n",
        "        h0 = h0.unsqueeze(0).repeat(self.decoder.n_layers,1,1).contiguous()\n",
        "        c0 = c0.unsqueeze(0).repeat(self.decoder.n_layers,1,1).contiguous()\n",
        "        dec_hidden = (h0, c0)\n",
        "\n",
        "        input_tok = tgt[:,0]\n",
        "        for t in range(1, T):\n",
        "            logits, dec_hidden = self.decoder(input_tok, dec_hidden)\n",
        "            outputs[:,t,:] = logits\n",
        "            teacher_force = (torch.rand(1).item() < teacher_forcing_ratio)\n",
        "            top1 = logits.argmax(1)\n",
        "            input_tok = tgt[:,t] if teacher_force else top1\n",
        "        return outputs\n",
        "\n",
        "# Instantiate model\n",
        "enc = Encoder(len(src_vocab), emb_dim=EMB_DIM, enc_hidden=ENC_HID, n_layers=ENC_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
        "dec = Decoder(len(bpe_token_to_id), emb_dim=EMB_DIM, dec_hidden=DEC_HID, n_layers=DEC_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
        "model = Seq2Seq(enc, dec).to(DEVICE)\n",
        "print(\"Vanilla Model ready. #params:\", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLkSUDp4UqjI",
        "outputId": "f80969f0-6fc8-44c1-a417-26cc442dffc3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Vanilla Model ready. #params: 6536893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Training Loop (50 epochs max, early stopping, timing in seconds, train/val accuracy + loss + ppl)\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import math\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX_TGT)\n",
        "\n",
        "# Adjustable for experiments\n",
        "LR = 5e-4  # Suggested: 1e-3, 5e-4, 1e-4\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "N_EPOCHS = 50\n",
        "CLIP = 1.0\n",
        "PATIENCE = 5   # stop if no improvement for 5 consecutive epochs\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, criterion, clip=CLIP):\n",
        "    model.train()\n",
        "    epoch_loss, correct, total = 0, 0, 0\n",
        "    for src, src_lens, tgt, tgt_lens in dataloader:\n",
        "        src, src_lens, tgt = src.to(DEVICE), src_lens.to(DEVICE), tgt.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lens, tgt, teacher_forcing_ratio=0.5)\n",
        "        output_dim = output.shape[-1]\n",
        "        logits = output[:, 1:].reshape(-1, output_dim)\n",
        "        targets = tgt[:, 1:].reshape(-1)\n",
        "        loss = criterion(logits, targets)\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        preds = logits.argmax(1)\n",
        "        mask = targets != PAD_IDX_TGT\n",
        "        correct += (preds.eq(targets) & mask).sum().item()\n",
        "        total += mask.sum().item()\n",
        "    acc = correct / total if total > 0 else 0\n",
        "    return epoch_loss / len(dataloader), acc\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for src, src_lens, tgt, tgt_lens in dataloader:\n",
        "            src, src_lens, tgt = src.to(DEVICE), src_lens.to(DEVICE), tgt.to(DEVICE)\n",
        "            output = model(src, src_lens, tgt, teacher_forcing_ratio=0.0)\n",
        "            output_dim = output.shape[-1]\n",
        "            logits = output[:, 1:].reshape(-1, output_dim)\n",
        "            targets = tgt[:, 1:].reshape(-1)\n",
        "            loss = criterion(logits, targets)\n",
        "            epoch_loss += loss.item()\n",
        "            preds = logits.argmax(1)\n",
        "            mask = targets != PAD_IDX_TGT\n",
        "            correct += (preds.eq(targets) & mask).sum().item()\n",
        "            total += mask.sum().item()\n",
        "    acc = correct / total if total > 0 else 0\n",
        "    return epoch_loss / len(dataloader), acc\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(1, N_EPOCHS+1):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_epoch(model, train_dl, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dl, criterion)\n",
        "    valid_ppl = math.exp(valid_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), \"best_seq2seq.pt\")\n",
        "        patience_counter = 0\n",
        "        print(f\"{epoch}: Train Loss={train_loss:.3f},Train Acc={train_acc*100:.2f}%, \"\n",
        "              f\"Valid Loss={valid_loss:.3f},Valid Acc={valid_acc*100:.2f}%, Valid PPL={valid_ppl:.2f}, \"\n",
        "              f\"Time={elapsed:.2f}s  <-- saved\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"{epoch}: Train Loss={train_loss:.3f},Train Acc={train_acc*100:.2f}%, \"\n",
        "              f\"Valid Loss={valid_loss:.3f},Valid Acc={valid_acc*100:.2f}%, Valid PPL={valid_ppl:.2f}, \"\n",
        "              f\"Time={elapsed:.2f}s  (no improvement {patience_counter}/{PATIENCE})\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4FuWfkHU0jk",
        "outputId": "b155b7b2-10e8-4ff0-8582-f1dcbc8a9787"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Train Loss=6.252,Train Acc=9.84%, Valid Loss=6.069,Valid Acc=10.86%, Valid PPL=432.09, Time=51.52s  <-- saved\n",
            "2: Train Loss=5.961,Train Acc=11.42%, Valid Loss=6.060,Valid Acc=10.97%, Valid PPL=428.46, Time=52.39s  <-- saved\n",
            "3: Train Loss=5.881,Train Acc=11.68%, Valid Loss=6.061,Valid Acc=10.86%, Valid PPL=428.93, Time=51.63s  (no improvement 1/5)\n",
            "4: Train Loss=5.806,Train Acc=11.92%, Valid Loss=6.062,Valid Acc=10.97%, Valid PPL=429.12, Time=51.75s  (no improvement 2/5)\n",
            "5: Train Loss=5.754,Train Acc=12.14%, Valid Loss=6.062,Valid Acc=10.86%, Valid PPL=429.26, Time=51.78s  (no improvement 3/5)\n",
            "6: Train Loss=5.707,Train Acc=12.34%, Valid Loss=6.067,Valid Acc=10.86%, Valid PPL=431.18, Time=51.96s  (no improvement 4/5)\n",
            "7: Train Loss=5.664,Train Acc=12.65%, Valid Loss=6.069,Valid Acc=10.86%, Valid PPL=432.16, Time=52.69s  (no improvement 5/5)\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Evaluation (BLEU, Perplexity, CER) with Vanilla model\n",
        "\n",
        "# --- Install dependencies if missing ---\n",
        "try:\n",
        "    import sacrebleu\n",
        "except ImportError:\n",
        "    !pip install sacrebleu --quiet\n",
        "    import sacrebleu\n",
        "\n",
        "try:\n",
        "    import editdistance\n",
        "except ImportError:\n",
        "    !pip install editdistance --quiet\n",
        "    import editdistance\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# --- BPE Decode Function ---\n",
        "def bpe_decode(tokens):\n",
        "    words, current_word = [], \"\"\n",
        "    for tok in tokens:\n",
        "        if tok.endswith(\"</w>\"):\n",
        "            current_word += tok.replace(\"</w>\", \"\")\n",
        "            words.append(current_word)\n",
        "            current_word = \"\"\n",
        "        else:\n",
        "            current_word += tok\n",
        "    if current_word:\n",
        "        words.append(current_word)\n",
        "    return \" \".join(words)\n",
        "\n",
        "# --- Metrics Computation ---\n",
        "def compute_metrics(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    refs, hyps = [], []\n",
        "    test_loss = 0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for src, src_lens, tgt, tgt_lens in dataloader:\n",
        "            src, src_lens, tgt = src.to(DEVICE), src_lens.to(DEVICE), tgt.to(DEVICE)\n",
        "            output = model(src, src_lens, tgt, teacher_forcing_ratio=0.0)\n",
        "            output_dim = output.shape[-1]\n",
        "            logits = output[:, 1:].reshape(-1, output_dim)\n",
        "            targets = tgt[:, 1:].reshape(-1)\n",
        "            loss = criterion(logits, targets)\n",
        "            test_loss += loss.item()\n",
        "            num_batches += 1\n",
        "            preds = output.argmax(-1).cpu().numpy()\n",
        "            for i in range(len(src)):\n",
        "                # decode prediction\n",
        "                pred_tokens = [bpe_id_to_token[idx] for idx in preds[i] if idx in bpe_id_to_token]\n",
        "                if \"<eos>\" in pred_tokens:\n",
        "                    pred_tokens = pred_tokens[1:pred_tokens.index(\"<eos>\")]\n",
        "                else:\n",
        "                    pred_tokens = pred_tokens[1:]\n",
        "                hyp = bpe_decode(pred_tokens)\n",
        "\n",
        "                # decode reference\n",
        "                ref_tokens = [bpe_id_to_token[idx.item()] for idx in tgt[i] if idx.item() in bpe_id_to_token]\n",
        "                if \"<eos>\" in ref_tokens:\n",
        "                    ref_tokens = ref_tokens[1:ref_tokens.index(\"<eos>\")]\n",
        "                else:\n",
        "                    ref_tokens = ref_tokens[1:]\n",
        "                ref = bpe_decode(ref_tokens)\n",
        "\n",
        "                refs.append(ref)\n",
        "                hyps.append(hyp)\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
        "    cer = np.mean([\n",
        "        editdistance.eval(h, r) / len(r) if len(r) > 0 else 0\n",
        "        for h, r in zip(hyps, refs)\n",
        "    ])\n",
        "    test_loss /= num_batches\n",
        "    test_ppl = math.exp(test_loss)\n",
        "    return {\"BLEU\": bleu.score, \"PPL\": test_ppl, \"CER\": cer}\n",
        "\n",
        "# --- Load Best Model + Evaluate on test set ---\n",
        "model.load_state_dict(torch.load(\"best_seq2seq.pt\", map_location=DEVICE))\n",
        "metrics = compute_metrics(model, test_dl, criterion)\n",
        "print(\"Test metrics:\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUIkMUePVGfb",
        "outputId": "81480321-2537-479e-ae46-700810ecf3a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test metrics: {'BLEU': 0.0069640264920121115, 'PPL': 444.2004792065532, 'CER': np.float64(0.77819266987962)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Inference with Beam Search (adapted for vanilla)\n",
        "\n",
        "def translate_sentence(model, urdu_text, max_len=MAX_TGT_LEN, beam_size=3):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src_ids = torch.tensor([encode_src_line(urdu_text)], dtype=torch.long).to(DEVICE)\n",
        "        src_lens = torch.tensor([src_ids.size(1)], dtype=torch.long).to(DEVICE)\n",
        "        enc_out, (h_n, c_n) = model.encoder(src_ids, src_lens)\n",
        "        top_fwd, top_bwd = h_n[-2,:,:], h_n[-1,:,:]\n",
        "        top_c_fwd, top_c_bwd = c_n[-2,:,:], c_n[-1,:,:]\n",
        "        h0 = torch.tanh(model.h_proj(torch.cat((top_fwd, top_bwd), dim=1)))\n",
        "        c0 = torch.tanh(model.c_proj(torch.cat((top_c_fwd, top_c_bwd), dim=1)))\n",
        "        h0 = h0.unsqueeze(0).repeat(model.decoder.n_layers,1,1).contiguous()\n",
        "        c0 = c0.unsqueeze(0).repeat(model.decoder.n_layers,1,1).contiguous()\n",
        "        initial_hidden = (h0, c0)\n",
        "\n",
        "        # Beam: (tokens, hidden, score)\n",
        "        beams = [([SOS_ID], initial_hidden, 0.0)]\n",
        "        for _ in range(max_len):\n",
        "            new_beams = []\n",
        "            for seq, hidden, score in beams:\n",
        "                input_tok = torch.tensor([seq[-1]], dtype=torch.long).to(DEVICE)\n",
        "                logits, hidden = model.decoder(input_tok, hidden)\n",
        "                log_probs = torch.log_softmax(logits, dim=1)\n",
        "                topk = torch.topk(log_probs, beam_size)\n",
        "                for idx, log_prob in zip(topk.indices[0], topk.values[0]):\n",
        "                    new_seq = seq + [idx.item()]\n",
        "                    new_score = score + log_prob.item()\n",
        "                    new_beams.append((new_seq, hidden, new_score))\n",
        "            beams = sorted(new_beams, key=lambda x: x[2], reverse=True)[:beam_size]\n",
        "            if all(seq[-1] == EOS_ID for seq,_,_ in beams):\n",
        "                break\n",
        "        best_seq = beams[0][0][1:]  # skip <sos>\n",
        "        tokens = [bpe_id_to_token.get(idx, \"<unk>\") for idx in best_seq]\n",
        "        if \"<eos>\" in tokens:\n",
        "            tokens = tokens[:tokens.index(\"<eos>\")]\n",
        "        return bpe_decode(tokens)\n",
        "\n",
        "# Example test sentence\n",
        "sample = test.sample(1).iloc[0]\n",
        "sample_urdu = sample[\"urdu\"]\n",
        "ref_roman   = sample[\"roman\"]\n",
        "pred_roman  = translate_sentence(model, sample_urdu)\n",
        "\n",
        "print(\"Input Urdu:\", sample_urdu)\n",
        "print(\"Reference Roman:\", ref_roman)\n",
        "print(\"Predicted Roman:\", pred_roman)\n",
        "\n",
        "# Save the model after training\n",
        "torch.save(model.state_dict(), \"urdu_to_roman_urdu_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhbdwSUpVN6S",
        "outputId": "e358048a-5f69-488f-8b24-39a633991e47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Urdu: وہ رات ہے کوئی ذرہ بھی محو خواب نہیں\n",
            "Reference Roman: vo raat hai koi zarra bhi mahv e qhvab nahin\n",
            "Predicted Roman: vo e e e e e e e\n"
          ]
        }
      ]
    }
  ]
}